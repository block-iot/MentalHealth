{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7542657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import matplotlib\n",
    "\n",
    "nd = pd.read_csv('numeric_data.csv')\n",
    "print(nd.shape)\n",
    "\n",
    "output = [\"stais1\",\"stais3\",\"stais4\",\"stais5\",\"stais6\",\"stais7\",\"stais8\",\"stais9\",\"stais10\",\"stais11\",\"stais12\",\"stais13\",\n",
    "          \"stais14\",\"stais15\",\"stais16\",\"stais17\",\"stais18\",\"stais19\",\"stais20\",\n",
    "          \"sds_1\",\"sds_3\",\"sds_4\",\"sds_5\",\"sds_6\",\"sds_7\",\"sds_8\",\"sds_9\",\"sds_10\",\"sds_11\",\"sds_12\",\"sds_13\",\n",
    "          \"sds_14\",\"sds_15\",\"sds_16\",\"sds_17\",\"sds_18\",\"sds_19\",\"sds_20\"]\n",
    "target = ['stai_s_score', 'sds_score', 'stai_t_score', 'ucls_5', 'sh_score']\n",
    "\n",
    "data_y = nd.loc[:,output]\n",
    "data_x = nd\n",
    "\n",
    "columns = nd.columns.values\n",
    "\n",
    "for col in columns:\n",
    "    if col in output:\n",
    "        data_x = data_x.drop([col],axis = 1)\n",
    "        #print(col)\n",
    "    elif col in target:\n",
    "        data_x = data_x.drop([col],axis = 1)\n",
    "        #print(col)\n",
    "    elif nd[col].isna().sum() != 0:\n",
    "        data_x = data_x.drop([col],axis = 1)\n",
    "        #print(col)\n",
    "    elif nd[col].dtypes == object:\n",
    "        data_x = data_x.drop([col],axis = 1)\n",
    "        #print(nd[col].dtypes)\n",
    "\n",
    "    '''\n",
    "    elif not nd[col].dtypes is np.dtype('int64'):\n",
    "        if not nd[col].dtypes is np.dtype('float64'):\n",
    "            data_x = data_x.drop([col],axis = 1)\n",
    "            print(nd[col].dtypes)\n",
    "    ''' \n",
    "\n",
    "#data_y = nd.loc[:,[\"stai_s_score\"]]\n",
    "\n",
    "features_names = data_x.columns.values\n",
    "#print(len(features_names))\n",
    "print(features_names)\n",
    "\n",
    "copy_data_x = copy.deepcopy(data_x)\n",
    "\n",
    "data_x = np.array(data_x, dtype=np.float32)\n",
    "#print(data_x)\n",
    "data_y = np.array(data_y, dtype=np.float32)\n",
    "#print(data_y)\n",
    "\n",
    "#print(features_names)\n",
    "\n",
    "X = data_x[:1316]\n",
    "y = data_y[:1316]\n",
    "X_test = data_x[1316:]\n",
    "y_test = data_y[1316:]\n",
    "\n",
    "#print(data_x.shape)\n",
    "#print(data_y.shape)\n",
    "#print(data_t.shape)\n",
    "\n",
    "#print(X.shape)\n",
    "#print(y.shape)\n",
    "#print(X_test.shape)\n",
    "#print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4a5f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x1 = np.delete(X,slice(263),0)\n",
    "x2 = np.delete(X,slice(263,526),0)\n",
    "x3 = np.delete(X,slice(526,790),0)\n",
    "x4 = np.delete(X,slice(790,1053),0)\n",
    "x5 = X[:1053]\n",
    "\n",
    "\n",
    "y1 = np.delete(y,slice(263),0)\n",
    "y2 = np.delete(y,slice(263,526),0)\n",
    "y3 = np.delete(y,slice(526,790),0)\n",
    "y4 = np.delete(y,slice(790,1053),0)\n",
    "y5 = y[:1053]\n",
    "\n",
    "X_groups = [x1,x2,x3,x4,x5]\n",
    "y_groups = [y1,y2,y3,y4,y5]\n",
    "X_vali = [X[:263],X[263:526],X[526:790],X[790:1053],X[1053:]]\n",
    "y_vali = [y[:263],y[263:526],y[526:790],y[790:1053],y[1053:]]\n",
    "\n",
    "\n",
    "class TwoLayerNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(TwoLayerNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 100\n",
    "output_size = y.shape[1]\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "# Training\n",
    "mse = 0\n",
    "for i in range(5):\n",
    "    X_tensor = torch.tensor(X_groups[i])\n",
    "    y_tensor = torch.tensor(y_groups[i])\n",
    "    \n",
    "    X_validation = torch.tensor(X_vali[i])\n",
    "    y_validation = torch.tensor(y_vali[i])\n",
    "    \n",
    "    \n",
    "    model = TwoLayerNN(input_size, hidden_size, output_size)\n",
    "\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        outputs = model(X_tensor)\n",
    "        loss = criterion(outputs, y_tensor)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "    \n",
    "    predictions = model(X_validation)\n",
    "    loss = criterion(predictions, y_validation)\n",
    "    print(\"Validation loss:\",str(loss.item()))\n",
    "    mse += loss.item()\n",
    "\n",
    "CV_k = mse / 5\n",
    "print(CV_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f8f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(X)\n",
    "y_tensor = torch.tensor(y)\n",
    "\n",
    "\n",
    "model = TwoLayerNN(input_size, hidden_size, output_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    outputs = model(X_tensor)\n",
    "    loss = criterion(outputs, y_tensor)\n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test)\n",
    "y_test_tensor = torch.tensor(y_test)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "    test_loss = criterion(predictions, y_test_tensor)\n",
    "\n",
    "print(predictions)\n",
    "print(f\"Test Loss: {test_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754742db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stais_score(data):\n",
    "    return [sum(((5-data[0]),(data[1]),(data[2]),(5-data[3]),(data[4]),(data[5]),(5-data[6]),(data[7]),\n",
    "               (5-data[8]),(5-data[9]),(data[10]),(data[11]),(data[12]),(5-data[13]),(5-data[14]),\n",
    "               (data[15]),(data[16]),(5-data[17]),(5-data[18])))#,\n",
    "            #sum(((data[19]),(data[20]),(data[21]),(5-data[22]),(5-data[23]),(data[24]),(data[25]),(data[26]),\n",
    "               #(data[27]),(5-data[28]),(5-data[29]),(data[30]),(5-data[31]),(data[32]),(5-data[33]),\n",
    "               #(5-data[34]),(5-data[35]),(data[36]),(5-data[37])))\n",
    "           ]\n",
    "\n",
    "def sds_score(data):\n",
    "    return [sum(((data[19]),(data[20]),(data[21]),(5-data[22]),(5-data[23]),(data[24]),(data[25]),(data[26]),\n",
    "               (data[27]),(5-data[28]),(5-data[29]),(data[30]),(5-data[31]),(data[32]),(5-data[33]),\n",
    "               (5-data[34]),(5-data[35]),(data[36]),(5-data[37])))\n",
    "           ]\n",
    "\n",
    "print(1)\n",
    "#print([int(i+0.5) for i in predictions[0]])\n",
    "#print(y_test[0].shape)\n",
    "'''\n",
    "predict = predictions.tolist()\n",
    "#print(predict)\n",
    "\n",
    "p_scores = [scores(i) for i in predict]\n",
    "y_scores = [scores(i) for i in y_test]\n",
    "#print(p_scores)\n",
    "\n",
    "p_sc = [[int(i[0]+0.5),int(i[1]+0.5)] for i in p_scores]\n",
    "y_sc = [[int(j[0]),int(j[1])] for j in y_scores]\n",
    "#print(p_sc)\n",
    "#print()\n",
    "#print(y_sc)\n",
    "\n",
    "\n",
    "p_s = torch.tensor(p_scores)\n",
    "y_s = torch.tensor(y_scores)\n",
    "\n",
    "\n",
    "l = criterion(p_s, y_s)\n",
    "print(\"\\nMSEloss:\")\n",
    "print(l.item())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d7183",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dictionary = pd.read_csv(\"t1_data_dictionary.csv\")\n",
    "data_dictionary[\"Field Type\"].unique()\n",
    "\n",
    "data_dictionary.drop_duplicates(subset=\"Field Type\")\n",
    "\n",
    "\n",
    "categorical_df = data_dictionary[data_dictionary[\"Field Type\"].isin([\"radio\", \"dropdown\", \"checkbox\", \"slider\"])]\n",
    "categorical_cols = set(categorical_df[\"Variable / Field Name\"].tolist())\n",
    "#print(categorical_cols)\n",
    "\n",
    "#categorical_indices = [i for i in range(len(features_names)) if features_names[i] in categorical_cols]\n",
    "categorical_indices = []\n",
    "for i in range(len(features_names)):\n",
    "    for j in categorical_cols:\n",
    "        if j in features_names[i]:\n",
    "            categorical_indices.append(i)\n",
    "print(categorical_indices)\n",
    "\n",
    "print([features_names[i] for i in range(len(features_names)) if i in categorical_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45fe185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lime\n",
    "from lime import lime_tabular\n",
    "\n",
    "def predict_f1(data, model = model):\n",
    "    X_tensor = torch.FloatTensor(data)\n",
    "    predictions = model(X_tensor)\n",
    "    predict = np.array(predictions.tolist(), dtype=np.float32)\n",
    "    #print(predict)\n",
    "    p_scores = np.array([stais_score(i) for i in predict])\n",
    "    return p_scores\n",
    "\n",
    "def predict_f2(data, model = model):\n",
    "    X_tensor = torch.FloatTensor(data)\n",
    "    predictions = model(X_tensor)\n",
    "    predict = np.array(predictions.tolist(), dtype=np.float32)\n",
    "    #print(predict)\n",
    "    p_scores = np.array([sds_score(i) for i in predict])\n",
    "    return p_scores\n",
    "\n",
    "testD = X_test[:10]\n",
    "#yscores = [scores(i) for i in y_test[:10]]\n",
    "\n",
    "p1 = predict_f1(data = testD, model = model)\n",
    "print(p1)\n",
    "\n",
    "p2 = predict_f2(data = testD, model = model)\n",
    "print(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0688f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "targets = [\"stai_s_score\"]#, 'sds_score']\n",
    "\n",
    "explainer = lime_tabular.LimeTabularExplainer(training_data = X, \n",
    "                                                   mode = \"regression\",\n",
    "                                                   feature_names = features_names,\n",
    "                                                   categorical_features = categorical_indices,\n",
    "                                                   class_names = targets, \n",
    "                                                   discretize_continuous = True)\n",
    "\n",
    "\n",
    "importance = {}\n",
    "count = {}\n",
    "\n",
    "for j in range(1):\n",
    "    for j in range(X_test.shape[0]):\n",
    "        exp = explainer.explain_instance(data_row = X_test[j], predict_fn = predict_f1, num_features = X_test.shape[1])\n",
    "        exp.show_in_notebook(show_table = True)\n",
    "        a = exp.as_list()\n",
    "        #print(a)\n",
    "        features = []\n",
    "        \n",
    "        for i in range(len(a)):\n",
    "            keys0 = a[i][0].split(' ')\n",
    "            if (\"=\" in keys0[0]):\n",
    "                keys = keys0[0].split(\"=\")\n",
    "                keys = keys[0].split(\"__\")\n",
    "                key = keys[0]\n",
    "            \n",
    "            else: \n",
    "                keys = keys0\n",
    "                if keys[0][0].isalpha():\n",
    "                    key = keys[0]\n",
    "                else:\n",
    "                    key = keys[2]\n",
    "            \n",
    "            if key in importance:\n",
    "                importance[key] += abs(a[i][1])\n",
    "                count[key] += 1\n",
    "            else:\n",
    "                importance[key] = abs(a[i][1])\n",
    "                count[key] = 1\n",
    "            \n",
    "            features.append(key)\n",
    "            \n",
    "        print(features)\n",
    "\n",
    "print(importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a88384",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape[0])\n",
    "print(sorted(importance.items(), key = lambda kv:(-kv[1], kv[0]))[:50])\n",
    "print(sorted(count.items(), key = lambda kv:(-kv[1], kv[0]))[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bebaf2f-a1c5-4b36-b609-6665e4ad8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sortimportance = {}\n",
    "for f, c in importance.items():\n",
    "    sortimportance[f] = importance[f] / count[f]\n",
    "\n",
    "sortimportance = sorted(sortimportance.items(), key = lambda kv:(-abs(kv[1]), kv[0]))[:30]\n",
    "\n",
    "categories, frequencies = [], []\n",
    "for f, c in sortimportance:\n",
    "    categories.append(f)\n",
    "    frequencies.append(c)\n",
    "categories.reverse()\n",
    "frequencies.reverse()\n",
    "\n",
    "bar_color = []\n",
    "temp = {}\n",
    "color_count = 0\n",
    "\n",
    "for c in categories:\n",
    "    c = c.split(' ')\n",
    "    if (\"__\" in c[0]):\n",
    "        c = c[0].split(\"__\")[0]\n",
    "    else:\n",
    "        if c[0][0].isalpha():\n",
    "            c = c[0]\n",
    "        else:\n",
    "            c = c[2]\n",
    "\n",
    "    if c in temp:\n",
    "        bar_color.append(temp[c])\n",
    "    else:\n",
    "        temp[c] = list(matplotlib.colors.XKCD_COLORS.values())[color_count]\n",
    "        color_count += 1\n",
    "        bar_color.append(temp[c])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.barh(categories, frequencies, color=bar_color)\n",
    "\n",
    "\n",
    "plt.title('Bar Chart of Average_Importance by Category')\n",
    "plt.ylabel('Categories')\n",
    "plt.xlabel('Average_Importance')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f05ede8-666a-43cf-86c3-4f8f3b7a89b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sortimportance = {}\n",
    "for f, c in importance.items():\n",
    "    sortimportance[f] = importance[f] / count[f]\n",
    "\n",
    "sortimportance = sorted(sortimportance.items(), key = lambda kv:(-abs(kv[1]), kv[0]))[:30]\n",
    "\n",
    "categories, frequencies = [], []\n",
    "for f, c in sortimportance:\n",
    "    categories.append(f)\n",
    "    frequencies.append(c)\n",
    "categories.reverse()\n",
    "frequencies.reverse()\n",
    "\n",
    "bar_color = []\n",
    "temp = {}\n",
    "color_count = 0\n",
    "\n",
    "for c in categories:\n",
    "    c = c.split(' ')\n",
    "    if (\"__\" in c[0]):\n",
    "        c = c[0].split(\"__\")[0]\n",
    "    else:\n",
    "        if c[0][0].isalpha():\n",
    "            c = c[0]\n",
    "        else:\n",
    "            c = c[2]\n",
    "\n",
    "    if c in temp:\n",
    "        bar_color.append(temp[c])\n",
    "    else:\n",
    "        temp[c] = list(matplotlib.colors.XKCD_COLORS.values())[color_count]\n",
    "        color_count += 1\n",
    "        bar_color.append(temp[c])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.barh(categories, frequencies, color=bar_color)\n",
    "\n",
    "\n",
    "plt.title('Bar Chart of Average_Importance by Category')\n",
    "plt.ylabel('Categories')\n",
    "plt.xlabel('Average_Importance')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209a4d90-69c9-47c5-ac09-1bdc17d8526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sortimportance = sorted(importance.items(), key = lambda kv:(-kv[1], kv[0]))\n",
    "#sortcount = sorted(count.items(), key = lambda kv:(-kv[1], kv[0]))\n",
    "\n",
    "categories, frequencies = [], []\n",
    "for f, c in sortimportance:\n",
    "    categories.append(f)\n",
    "    frequencies.append(importance[f] / count[f])\n",
    "    #print(f, importance[f], count[f])\n",
    "categories.reverse()\n",
    "frequencies.reverse()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.barh(categories, frequencies, color='lightblue')\n",
    "\n",
    "\n",
    "plt.title('Bar Chart of Frequencies by Category')\n",
    "plt.ylabel('Categories')\n",
    "plt.xlabel('Frequencies')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a64e4-c7e6-4a40-8cb1-80e2c22d0e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_tabular.LimeTabularExplainer(training_data = X, \n",
    "                                                   mode = \"regression\",\n",
    "                                                   feature_names = features_names,\n",
    "                                                   categorical_features = categorical_indices,\n",
    "                                                   #class_names = targets, \n",
    "                                                   discretize_continuous = True)\n",
    "\n",
    "\n",
    "importance2 = {}\n",
    "count2 = {}\n",
    "\n",
    "for i in range(1):\n",
    "    for j in range(X_test.shape[0]):\n",
    "        exp = explainer.explain_instance(data_row = X_test[j], predict_fn = predict_f1, num_features = X_test.shape[1])\n",
    "        exp.show_in_notebook(show_table = True)\n",
    "        a = exp.as_list()\n",
    "        #print(a)\n",
    "        features = []\n",
    "        \n",
    "        for i in range(len(a)):\n",
    "            keys = a[i][0]\n",
    "            \n",
    "            if keys in importance2:\n",
    "                importance2[keys] += a[i][1]\n",
    "                count2[keys] += 1\n",
    "            else:\n",
    "                importance2[keys] = a[i][1]\n",
    "                count2[keys] = 1\n",
    "            \n",
    "            features.append(keys)\n",
    "            \n",
    "        print(features)\n",
    "\n",
    "print(importance2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b424b5b-0eac-43a9-b8d3-ef53edef8a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape[0])\n",
    "print(sorted(importance2.items(), key = lambda kv:(-abs(kv[1]), kv[0]))[:50])\n",
    "print(sorted(count2.items(), key = lambda kv:(-kv[1], kv[0]))[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a8b83-fcdf-40ce-8ef3-7d95de1872f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sortimportance = sorted(importance2.items(), key = lambda kv:(-abs(kv[1]), kv[0]))\n",
    "#sortcount = sorted(count.items(), key = lambda kv:(-kv[1], kv[0]))\n",
    "\n",
    "categories, frequencies = [], []\n",
    "for f, c in sortimportance:\n",
    "    categories.append(f)\n",
    "    frequencies.append(importance2[f] / count2[f])\n",
    "    #print(f, importance[f], count[f])\n",
    "categories.reverse()\n",
    "frequencies.reverse()\n",
    "\n",
    "\n",
    "bar_color = []\n",
    "temp = {}\n",
    "color_count = 0\n",
    "\n",
    "for c in categories:\n",
    "    c = c.split(' ')\n",
    "    if (\"=\" in c[0]):\n",
    "        c = c[0].split(\"=\")[0].split(\"__\")[0]\n",
    "    else:\n",
    "        if c[0][0].isalpha():\n",
    "            c = c[0]\n",
    "        else:\n",
    "            c = c[2]\n",
    "\n",
    "    if c in temp:\n",
    "        bar_color.append(temp[c])\n",
    "    else:\n",
    "        temp[c] = list(matplotlib.colors.XKCD_COLORS.values())[color_count] #matplotlib.colors.Colormap(color_count)\n",
    "        color_count += 1\n",
    "        bar_color.append(temp[c])\n",
    "\n",
    "#print(bar_color)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 30))\n",
    "plt.barh(categories, frequencies, color= bar_color)\n",
    "\n",
    "\n",
    "plt.title('Bar Chart of Frequencies by Category')\n",
    "plt.ylabel('Categories')\n",
    "plt.xlabel('Frequencies')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09e0315-8b96-4991-9bce-60f7134c94d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sortimportance = {}\n",
    "for f, c in importance2.items():\n",
    "    sortimportance[f] = importance2[f] / count2[f]\n",
    "\n",
    "sortimportance = sorted(sortimportance.items(), key = lambda kv:(-abs(kv[1]), kv[0]))[:50]\n",
    "#sortcount = sorted(count.items(), key = lambda kv:(-kv[1], kv[0]))\n",
    "\n",
    "categories, frequencies = [], []\n",
    "for f, c in sortimportance:\n",
    "    categories.append(f)\n",
    "    frequencies.append(c)\n",
    "categories.reverse()\n",
    "frequencies.reverse()\n",
    "\n",
    "bar_color = []\n",
    "temp = {}\n",
    "color_count = 0\n",
    "\n",
    "for c in categories:\n",
    "    c = c.split(' ')\n",
    "    if (\"=\" in c[0]):\n",
    "        c = c[0].split(\"=\")[0].split(\"__\")[0]\n",
    "    else:\n",
    "        if c[0][0].isalpha():\n",
    "            c = c[0]\n",
    "        else:\n",
    "            c = c[2]\n",
    "\n",
    "    if c in temp:\n",
    "        bar_color.append(temp[c])\n",
    "    else:\n",
    "        temp[c] = list(matplotlib.colors.XKCD_COLORS.values())[color_count]\n",
    "        color_count += 1\n",
    "        bar_color.append(temp[c])\n",
    "\n",
    "#print(bar_color)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.barh(categories, frequencies, color=bar_color)\n",
    "\n",
    "\n",
    "plt.title('Bar Chart of Frequencies by Category')\n",
    "plt.ylabel('Categories')\n",
    "plt.xlabel('Frequencies')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c955ba-2c38-4bc8-afd3-877b1b084e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sortimportance = {}\n",
    "for f, c in importance2.items():\n",
    "    sortimportance[f] = importance2[f] / count2[f]\n",
    "\n",
    "sortimportance = sorted(sortimportance.items(), key = lambda kv:(-abs(kv[1]), kv[0]))\n",
    "#sortcount = sorted(count.items(), key = lambda kv:(-kv[1], kv[0]))\n",
    "\n",
    "categories, frequencies = [], []\n",
    "for f, c in sortimportance:\n",
    "    categories.append(f)\n",
    "    frequencies.append(c)\n",
    "categories.reverse()\n",
    "frequencies.reverse()\n",
    "\n",
    "bar_color = []\n",
    "temp = {}\n",
    "color_count = 0\n",
    "\n",
    "for c in categories:\n",
    "    c = c.split(' ')\n",
    "    if (\"=\" in c[0]):\n",
    "        c = c[0].split(\"=\")[0].split(\"__\")[0]\n",
    "    else:\n",
    "        if c[0][0].isalpha():\n",
    "            c = c[0]\n",
    "        else:\n",
    "            c = c[2]\n",
    "\n",
    "    if c in temp:\n",
    "        bar_color.append(temp[c])\n",
    "    else:\n",
    "        temp[c] = list(matplotlib.colors.XKCD_COLORS.values())[color_count]\n",
    "        color_count += 1\n",
    "        bar_color.append(temp[c])\n",
    "\n",
    "#print(bar_color)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.barh(categories, frequencies, color=bar_color)\n",
    "\n",
    "\n",
    "plt.title('Bar Chart of Frequencies by Category')\n",
    "plt.ylabel('Categories')\n",
    "plt.xlabel('Frequencies')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf1977e-447b-4475-be2c-c99f87762769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
